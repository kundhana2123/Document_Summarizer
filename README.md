# AskMyDoc: Upload, Summarize, and Ask Anything
## INTRODUCTION
AskMyDoc is a Streamlit-based platform that allows users to upload documents (PDF, TXT, DOCX) and ask questions. It leverages LangChain, HuggingFace embeddings, sentiment analysis, and RAG architecture for document retrieval and summarization.

## EXAMPLE USAGE
• Install modules : pip install -r requirements.txt<br/>
• Run command : streamlit run Askmydoc_streamlit.py<br/>
• Uploading a Document: Users can upload a document in PDF, TXT, or DOCX format after which a summary is generated automatically after successful upload.<br/>
• Asking a Question: After the document is uploaded and processed, users can type in a question related to the content of the document.<br/>
• Getting an Answer: The system retrieves relevant context from the document and generates an answer, considering the sentiment of the user's question.<br/>

## ARCHITECTURE: RAG (RETREIVAL-AUGMENTED GENERATION)
The system is built using RAG architecture, which is a hybrid approach combining retrieval-based techniques with generative models such as llms.<br/>
The process follows these main steps:<br/>
• Document Upload: Users upload a document in PDF, TXT, or DOCX format.<br/>
• Document Parsing & Retrival: The uploaded file is parsed to extract its text content, which is then split into smaller chunks and using vector store (Chroma), the relevant sections of the document are retrieved based on the user's query.<br/>
• Sentiment Analysis: Sentiment analysis is applied to the user’s question to understand the tone (positive, negative, or neutral). <br/>
• Answer Generation: The system uses a Large Language Model (LLM) to generate an answer by integrating the retrieved context with the sentiment of the question.<br/>

## MODELS USED :
• HuggingFace Embeddings: The model all-MiniLM-L6-v2 is used to convert text into numerical embeddings. This allows for fast and accurate searching within large datasets. <br/>
• Ollama LLM: The llama3.2 model is used for generating detailed, formal responses to user queries. It is fine-tuned to handle complex document-based questions. <br/>
• Sentiment Analysis: We analyze the sentiment of the user's input, and incorporate into the prompt to generate responses that match the user's tone. <br/>
• LangChain is a framework used here with custom prompt templates to format the context, question, and sentiment together before passing it to the LLM. <br/>
• Streamlit is used to create an interactive front-end interface. Streamlit also handles displaying the results and document summaries. <br/>
• Chroma is used as the vector store to manage and query document embeddings allowing for fast retrieval of relevant information based on the user's question. <br/>

## SENTIMENT ANALYSIS
• Sentiment analysis is a key feature of the system. <br/>
• It involves classifying the user's input into one of three sentiment categories: Positive, Negative, or Neutral. <br/> 
• This classification helps tailor the tone of the answer generated by the system, ensuring that the response aligns with the emotional tone of the user's inquiry.<br/>

## PASSWORD SECURITY
The system includes a security feature that checks if a user query requests sensitive personal information such as passwords, social security numbers (SSNs), phone numbers, or other private data. If such information is detected, the system ensures it is omitted and responds with a message like, "I cannot provide that information due to privacy and security concerns," or "I don't have enough information to answer that." This feature is built into the query handling process, ensuring the system remains secure by not disclosing any private or sensitive data.
